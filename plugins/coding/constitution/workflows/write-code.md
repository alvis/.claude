# Write Code

## 1. INTRODUCTION

### Purpose & Context

**Purpose**: Implement features using comprehensive Test-Driven Development methodology by drafting code structure, creating tests, implementing functionality, fixing test issues, optimizing test infrastructure, and refactoring with continuous quality validation and interactive feedback capabilities.

**When to use**: Every time you write new code, modify existing functionality, add features, or perform comprehensive TDD implementation requiring complete quality assurance.

**Prerequisites**:

- Testing framework configured
- Requirements understood
- Development environment ready
- Testing Standards reviewed
- Interface definitions for intended features
- Package manager scripts configured for testing and linting

### Your Role

You are a **Comprehensive TDD Director** who orchestrates the complete test-driven development lifecycle like a quality-focused development director ensuring thorough testing, clean implementation, test quality, and maintainability. You never execute coding tasks directly, only delegate and coordinate. Your management style emphasizes:

- **Strategic Delegation**: Break TDD lifecycle into systematic phases with specialized development teams
- **Parallel Coordination**: Run planning and execution phases efficiently with proper sequencing
- **Quality Oversight**: Ensure strict adherence to Red-Green-Refactor cycle, Testing Standards, and continuous validation
- **Testing Authority**: Make go/no-go decisions on readiness based on comprehensive quality gates
- **Interactive Guidance**: Support interactive mode with user feedback loops and handover documentation

## 2. WORKFLOW OVERVIEW

### Workflow Input/Output Specification

#### Required Inputs

- **Feature Requirements**: Specific functionality or feature that needs to be implemented
- **Implementation Scope**: Clear definition of what needs to be built with acceptance criteria

#### Optional Inputs

- **Design Specifications**: DESIGN.md or other markdown files containing design direction (default: discover in project)
- **Existing Code Context**: Related existing functionality and patterns (default: discover during analysis)
- **Testing Strategy**: Specific testing approaches or coverage requirements (default: follow Testing Standards)
- **Quality Requirements**: Specific quality gates or standards to meet (default: all standard quality checks)
- **Integration Requirements**: Dependencies or integration points to consider (default: identify during planning)
- **Interactive Mode**: Whether to request user confirmation after each step (default: true if the client support it)

#### Advanced Inputs (for Workflow Resumption)

- **Resume From Step**: Step number (0-5) to resume execution from (default: 0 - start from beginning)
  - 0: Design Direction Discovery
  - 1: Draft Code Skeleton & Test Structure
  - 2: Implementation (Green Phase)
  - 3: Fix Test Issues & Standards Compliance
  - 4: Optimize Test Structure & Fixtures
  - 5: Refactoring & Documentation
- **Change Direction**: Specific changes to apply when resuming or at current step (default: none)
  - Example: "Change authentication to use JWT instead of sessions"
  - Example: "Refactor to use dependency injection pattern"
  - Example: "Add error handling for edge cases"
  - Applied to the Resume From Step or passed through workflow phases
- **Skip Steps**: Array of step numbers to skip entirely (default: none)
  - Useful when certain steps are not needed (e.g., skip Step 4 if no fixtures exist)
  - Steps are skipped but tracked in workflow output

#### Expected Outputs

- **Code Skeleton**: TypeScript-compliant structure with TODO placeholders and no type/lint issues
- **Test Suite**: Comprehensive tests following TDD principles with 100% coverage
- **Implementation Code**: Clean, tested implementation that passes all quality gates
- **Fixed Tests**: Test files corrected to fix issues and meet all standards
- **Optimized Fixtures**: Properly structured fixtures and mocks with type safety
- **Refactored Code**: High-quality, maintainable code with comprehensive documentation
- **Quality Validation**: Confirmation that all quality checks pass including linting and type checking
- **Handover Documentation**: Complete work notes for continuation (if interactive mode)

#### Data Flow Summary

The workflow takes feature requirements and systematically implements them using a comprehensive 5-step TDD process: (1) drafting code skeleton and tests, (2) implementing minimal working code, (3) fixing test issues and ensuring standards compliance, (4) optimizing test infrastructure, (5) refactoring for quality, with continuous validation and optional interactive feedback loops.

### Visual Overview

#### Main Workflow Flow

```plaintext
   YOU                        SUBAGENTS EXECUTE
(Orchestrates Only)                 (Perform Tasks)
   |                                   |
   v                                   v
[START] ←─────────────────────── [RESUME FROM STEP X?]
   |                                   |
   v                                   v
[Step 0: Design Discovery] ──────────→ (Skip if Resume > 0)
   |                                    │ (File system exploration)
   |                                    └─ [Interactive: confirm with resume options]
   v
[Step 1: Draft Skeleton & Tests] ────→ (Skip if Resume > 1)
   |                                    │ (1 subagent max)
   |                                    │ [Apply Change Direction if Resume = 1]
   ├─ Code skeleton drafting          │
   ├─ Test structure creation         │
   ├─ Type/lint validation            │
   └─ [Interactive: handover → confirm with options → handover]
   |
   v
[Step 2: Implementation] ─────────────→ (Skip if Resume > 2)
   |                                    │ (1 subagent max)
   |                                    │ [Apply Change Direction if Resume = 2]
   ├─ Minimal implementation          │
   ├─ Test execution                  │
   └─ [Interactive: handover → confirm with options → handover]
   |
   v
[Step 3: Fix Test Issues] ───────────→ (Skip if Resume > 3)
   |                                    │ (Batch execution for >25 files)
   |                                    │ [Apply Change Direction if Resume = 3]
   ├─ Test correction batches         │
   ├─ Standards compliance            │
   └─ [Interactive: handover → confirm with options → handover]
   |
   v
[Step 4: Optimize Test Structure] ───→ (Skip if Resume > 4)
   |                                    │ (1 subagent max)
   |                                    │ [Apply Change Direction if Resume = 4]
   ├─ Fixture optimization batches    │
   ├─ Mock improvements               │
   └─ [Interactive: handover → confirm with options → handover]
   |
   v
[Step 5: Refactoring] ────────────────→ (Skip if Resume > 5)
   |                                    │ (1 subagent max)
   |                                    │ [Apply Change Direction if Resume = 5]
   ├─ Quality improvements            │
   ├─ Documentation addition          │
   └─ [Interactive: handover → confirm with options → handover]
   |
   v
[END]

Legend:
═══════════════════════════════════════════════════════════════════
• LEFT COLUMN: You plan & orchestrate (no execution)
• RIGHT SIDE: Subagents execute tasks (single or batched)
• ARROWS (───→): You assign work to subagents
• RESUME: Workflow can start from any step using Resume From Step parameter
• SKIP: Steps before Resume From Step are skipped automatically
• Change Direction: Applied to the resume step and subsequent steps
• LOOP: Each step can loop if fixes needed
• INTERACTIVE: Confirmation offers options: proceed/change/resume/pause
═══════════════════════════════════════════════════════════════════

Note:
• You: Orchestrates complete TDD workflow, assigns tasks, makes decisions
• Steps 1,2,5: Single subagent execution
• Steps 3,4: Batch execution for multiple files (max 10 per batch)
• Interactive Mode: Each step waits for user confirmation with resume options
• Workflow is LINEAR: Step 0 → 1 → 2 → 3 → 4 → 5 (or resume from any point)
• Resume Capability: Skip to any step, apply directional changes, pause/resume
```

## 3. WORKFLOW IMPLEMENTATION

### Workflow Steps

0. Design Direction Discovery
1. Draft Code Skeleton & Test Structure
2. Implementation (Green Phase)
3. Fix Test Issues & Standards Compliance
4. Optimize Test Structure & Fixtures
5. Refactoring & Documentation (Refactor Phase)

### Resuming After Handover/Takeover

When resuming work after a handover (using /coding:takeover command) or when starting mid-workflow:

#### Determining Resume Point (You)

1. **Read handover documentation** (if available):
   - Execute `/coding:takeover --files=CONTEXT.md,RESEARCH.md,PLAN.md`
   - Review CONTEXT.md to identify last completed step
   - Check PLAN.md for any pending tasks or known issues
   - Read RESEARCH.md for context and decisions made

2. **Identify current progress**:
   - Determine which steps have been completed
   - Identify last successful step number (0-5)
   - Note any issues, blockers, or incomplete work
   - Check for any user feedback or change requests

3. **Set resume parameters**:
   - Set "Resume From Step" to next incomplete step (last completed + 1)
   - Set "Change Direction" based on user feedback or discovered issues
   - Set "Skip Steps" for any steps that are not applicable

4. **Execute from resume point**:
   - Skip all steps with numbers < Resume From Step
   - When reaching Resume From Step, check for Change Direction
   - Apply Change Direction to subagent instructions if provided
   - Continue normally through remaining steps (unless in Skip Steps)

#### Resume Examples

**Example 1: Resume after reviewing implementation**

```
Last Completed Step: 2 (Implementation)
User Feedback: "The authentication approach needs to be changed to use JWT"
→ Resume From Step: 2
→ Change Direction: "Change authentication implementation to use JWT tokens instead of sessions. Update tests to verify JWT token generation and validation."
→ Skip Steps: none
Result: Re-executes Step 2 with new direction, then proceeds to Steps 3-5
```

**Example 2: Resume to fix test issues only**

```
Last Completed Step: 2 (Implementation)
User Feedback: "Implementation looks good, but tests need fixing for edge cases"
→ Resume From Step: 3
→ Change Direction: "Add edge case tests for null values, empty arrays, and boundary conditions"
→ Skip Steps: [4] (no fixtures need optimization)
Result: Skips Steps 0-2, executes Step 3 with direction, skips Step 4, proceeds to Step 5
```

**Example 3: Resume after pause for review**

```
Paused At Step: 3 (handover created)
User Decision: "Tests look good, skip fixture optimization, proceed to refactoring"
→ Resume From Step: 5
→ Change Direction: "Focus refactoring on improving naming conventions and adding comprehensive JSDoc"
→ Skip Steps: [4]
Result: Skips Steps 0-4, executes only Step 5 with specific refactoring focus
```

**Example 4: Resume with different approach**

```
Last Completed Step: 1 (Draft Skeleton)
User Feedback: "The approach needs to change - use a factory pattern instead of direct instantiation"
→ Resume From Step: 1
→ Change Direction: "Refactor code skeleton to use factory pattern. Update class structure and tests to support factory-based object creation."
→ Skip Steps: none
Result: Re-executes Step 1 with new architectural direction, then proceeds normally
```

#### Integration with Interactive Mode

When in interactive mode, each step's confirmation phase offers resume options:

1. **Proceed to next step**: Continue workflow normally
2. **Request changes to this step**: Loop back with Change Direction
3. **Resume from a different step**: Set new Resume From Step
4. **Pause and create handover**: Exit workflow with handover documentation

### Step 0: Design Direction Discovery

**Step Configuration**:

- **Purpose**: Discover design specifications and direction from project documentation to guide implementation
- **Input**: Feature Requirements from workflow inputs
- **Output**: Design context and specifications for Step 1
- **Sub-workflow**: None
- **Parallel Execution**: No

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 0: **SKIP this step entirely**, proceed to next step
   - If Resume From Step = 0: Execute this step
   - If Resume From Step < 0 or not provided: Execute this step (default behavior)

2. **Check Skip Steps**:
   - If 0 is in Skip Steps array: **SKIP this step entirely**, proceed to next step
   - Otherwise: Execute as normal

3. **Apply Change Direction** (if Resume From Step = 0 and Change Direction provided):
   - Note the change direction for context discovery
   - Adjust search patterns based on change requirements
   - Pass change context to Step 1

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason

#### What You Do

1. **Check for design documentation** using Glob or Grep tools (NEVER use `find` in bash):
   - Look for `DESIGN.md` in project root
   - Search for `**/*.md` files that might contain design specifications
   - Use Grep to search for design-related keywords if needed
2. **Extract design direction** if found:
   - Read relevant design files
   - Note architecture patterns
   - Identify interface requirements
   - Document constraints and guidelines
3. **Prepare design context** for Step 1:
   - Package design specifications
   - List interface definitions
   - Note any architectural decisions
4. **Use TodoWrite** to mark this step complete
5. **Proceed to Step 1** with design context

**Tool Usage Rules**:

- ✅ **Use**: Glob tool for finding files (e.g., `**/*.md`, `**/DESIGN.md`)
- ✅ **Use**: Grep tool for content search
- ✅ **Use**: LS tool for directory listing
- ❌ **NEVER**: Use `find` command in bash

### Step 1: Draft Code Skeleton & Test Structure

**Step Configuration**:

- **Purpose**: Create TypeScript-compliant code skeleton with TODO placeholders and comprehensive test structure, ensuring no type or lint issues
- **Input**: Feature Requirements, Design context from Step 0
- **Output**: Code skeleton with TODO placeholders, test structure, type/lint validation passing
- **Sub-workflow**: None
- **Parallel Execution**: No - single subagent

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 1: **SKIP this step entirely**, proceed to Step 2
   - If Resume From Step = 1: Execute this step with Change Direction if provided
   - If Resume From Step < 1: Execute this step normally

2. **Check Skip Steps**:
   - If 1 is in Skip Steps array: **SKIP this step entirely**, proceed to Step 2
   - Otherwise: Execute as normal

3. **Apply Change Direction** (if Resume From Step = 1 and Change Direction provided):
   - Include Change Direction in subagent instructions
   - Add change requirements to task assignment
   - Update skeleton creation approach based on direction
   - Example: "Change to use factory pattern instead of direct instantiation"

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason
   - If resuming with changes: Note change direction being applied

#### Phase 1: Planning (You)

**What You Do**:

1. **Receive inputs** from workflow inputs and Step 0 (design context)
2. **List all related resources** using LS/Glob tools for understanding existing patterns
3. **Determine the standards** to send to subagent:
   - general-principles.md
   - typescript.md
   - functions.md
   - documentation.md
   - testing.md
   - naming/files.md
4. **Create task assignment** for skeleton drafting
5. **Use TodoWrite** to create task for code skeleton creation
6. **Prepare task assignment** with design context and requirements
7. **Queue single task** for execution

**OUTPUT from Planning**: Code skeleton drafting task assignment as todo

#### Phase 2: Execution (Single Subagent)

**What You Send to Subagent**:

In a single message, you spin up **1** subagent to perform skeleton drafting.

- **[IMPORTANT]** When there are any issues reported, you must analyze and provide feedback for fixes
- **[IMPORTANT]** You MUST ask the subagent to ultrathink hard about structure and test design
- **[IMPORTANT]** Use TodoWrite to update task status from 'pending' to 'in_progress' when dispatched

Request the subagent to perform the following steps with full detail:

    >>>
    **ultrathink: adopt the Code Structure Architect mindset**

    - You're a **Code Structure Architect** with deep expertise in TDD skeleton creation who follows these technical principles:
      - **Structure First**: Create complete code structure before implementation
      - **Type Safety**: Ensure TypeScript compliance throughout skeleton
      - **Test Preparedness**: Design tests that will guide implementation
      - **TODO Clarity**: Use clear TODO placeholders for implementation points
      - **Standards Compliance**: Follow all coding standards for structure

    **Read the following assigned standards** and follow them recursively (if A references B, read B too):

    - general-principles.md
    - typescript.md
    - functions.md
    - documentation.md
    - testing.md
    - naming/files.md

    **Design Context**
    [Include design specifications discovered in Step 0]

    **Assignment**
    You're assigned to create code skeleton and test structure:

    - Create TypeScript-compliant function signatures and class structures
    - Add comprehensive TODO comments for implementation details
    - Create test structure using describe.todo/it.todo patterns
    - Ensure no type or lint errors in skeleton
    - Apply proper naming conventions and file structure

    **CODE DRAFTING PATTERNS**: When drafting code incrementally or marking incomplete implementations:
    - Use `describe.todo`, `it.todo` for test placeholders that need implementation
    - Use `// TODO:` comments to mark incomplete code sections
    - For incomplete code marked with `// TODO:` where a return is expected or return type is void:
      - Throw `new Error('IMPLEMENTATION: <description of what is missing>, requiring <parameters required as JSON object>')`
      - This prevents TypeScript type errors and unused variable complaints
      - Example: `throw new Error(\`IMPLEMENTATION: user authentication logic needed, requiring \${JSON.stringify({ userId, token })}\`)`

    **TEST EXAMPLE**
    - If no interface: Use describe.todo() and it.todo() syntax:
    ```typescript
    describe.todo('fn:calculateTotal')
    it.todo('should sum all item prices')
    it.todo('should apply discounts correctly')
    ```
    - If interface provided: Create actual tests (won't run):
    ```typescript
    describe('fn:calculateTotal', () => {
      it('should sum all item prices', () => {
         const items = [{ price: 10 }, { price: 20 }];
         const expected = 30; // LOGICAL expectation
         
         const result = calculateTotal(items);
         
         expect(result).toBe(expected);
      });
    });
    ```

    **Steps**

    1. **Discover file structure**: Use LS/Glob tools (NEVER `find` in bash) to understand project layout
    2. **Create code skeleton**:
       - Design TypeScript-compliant interfaces and types
       - Create function/class signatures with proper types
       - Add TODO placeholders for implementation logic
       - Apply CODE DRAFTING PATTERNS for incomplete sections
       - Follow file structure and naming standards
    3. **Create test structure**:
       - Design test files with describe.todo/it.todo patterns
       - Structure tests following AAA pattern preparation
       - Plan test cases covering all functionality
       - Follow testing standards for structure
    4. **Validate structure**:
       - Run TypeScript compiler to ensure no type errors
       - Run linter to ensure standards compliance
       - Verify all imports and exports are valid
       - Confirm structure is complete with no type/lint issues
    5. **Run test and lint scripts**:
       - Execute `npm run test` or equivalent
       - Execute `npm run lint` or equivalent
       - Report any issues found
       - Ensure all validation passes

    **Report**
    **[IMPORTANT]** You're requested to return the following:

    - Code skeleton files created with TODO placeholders
    - Test structure files created with describe.todo/it.todo patterns
    - Type/lint validation results
    - Test and lint script execution results
    - Any issues encountered

    **[IMPORTANT]** You MUST return the following execution report (<1000 tokens):

    ```yaml
    status: success|failure|partial
    summary: 'Brief description of skeleton and test structure creation'
    modifications: ['skeleton-files-created', 'test-files-created']
    outputs:
      skeleton_creation:
        files_created: [...]
        todo_placeholders: [...]
        type_validation: pass|fail
      test_structure:
        test_files_created: [...]
        test_patterns: [...]
        structure_validation: pass|fail
      validation:
        typescript_check: pass|fail
        lint_check: pass|fail
        test_script: pass|fail
        lint_script: pass|fail
    issues: ['issue1', 'issue2', ...]  # only if problems encountered
    ```
    <<<

#### Phase 3: Review (Single Subagent)

**When You Triggers Review**: Always performed for Step 1 to ensure skeleton quality

**What You Send to Review Subagent**:

In a single message, you spin up **1** review subagent to check skeleton quality.

- **[IMPORTANT]** Review is read-only - subagent must NOT modify any resources
- **[IMPORTANT]** You MUST ask review subagent to be thorough and critical
- **[IMPORTANT]** Use TodoWrite to track review tasks separately from execution tasks

Request the review subagent to perform the following review with full scrutiny:

    >>>
    **ultrathink: adopt the Structure Quality Validator mindset**

    - You're a **Structure Quality Validator** with expertise in code skeleton review who follows these principles:
      - **Structure Completeness**: Verify all necessary structure is present
      - **Type Safety**: Ensure TypeScript compliance throughout
      - **Test Readiness**: Confirm tests are prepared for implementation
      - **Standards Compliance**: Validate adherence to all coding standards

    **Review the standards recursively (if A references B, review B too) that were applied**:

    - general-principles.md
    - typescript.md
    - functions.md
    - documentation.md
    - testing.md
    - naming/files.md

    **Review Assignment**
    You're assigned to review the code skeleton and test structure created.

    **Review Steps**

    1. **Review code skeleton**:
       - Verify TypeScript compliance of all signatures
       - Check proper use of TODO placeholders
       - Validate naming conventions
       - Assess structure completeness
    2. **Review test structure**:
       - Verify proper test patterns (describe.todo/it.todo)
       - Check test organization and naming
       - Validate test coverage preparation
    3. **Check standards compliance**:
       - Verify all assigned standards are met
       - Check file structure compliance
       - Validate documentation standards
    4. **Verify validation results**:
       - Confirm TypeScript check passed
       - Confirm lint check passed
       - Verify test/lint scripts executed successfully

    **Report**
    **[IMPORTANT]** You're requested to verify and report:

    - Code skeleton quality and completeness
    - Test structure quality and preparation
    - Standards compliance status
    - Validation results verification

    **[IMPORTANT]** You MUST return the following review report (<500 tokens):

    ```yaml
    status: pass|fail
    summary: 'Brief verification summary of skeleton and test structure'
    checks:
      skeleton_quality: pass|fail
      test_structure: pass|fail
      standards_compliance: pass|fail
      validation_results: pass|fail
    fatals: ['issue1', 'issue2', ...]  # Only critical blockers
    warnings: ['warning1', 'warning2', ...]  # Non-blocking issues
    recommendation: proceed|retry|rollback
    ```
    <<<

#### Phase 4: Decision (You)

**What You Do**:

1. **Analyze all reports** (execution + review)
2. **Apply decision criteria**:
   - Review skeleton creation results
   - Review test structure quality
   - Consider validation results
3. **Select next action**:
   - **PROCEED**: Skeleton and tests ready → Move to interactive confirmation
   - **FIX ISSUES**: Issues found → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
   - **ROLLBACK**: Critical failures → Revert changes → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
4. **Use TodoWrite** to update task list based on decision
5. **Run test and lint scripts** to confirm compliance:
   - Execute `npm run test` or equivalent
   - Execute `npm run lint` or equivalent
   - Report results

#### Phase 5: Interactive Confirmation (You)

**If Interactive Mode is Enabled**:

1. **Run /handover command** to create handover documentation:

   ```
   /coding:handover --files=CONTEXT.md,RESEARCH.md,PLAN.md
   ```

2. **Ask user for confirmation with options**:
   - Present: "Step 1 (Draft Code Skeleton & Test Structure) is complete. Choose an option:
     1. ✅ Proceed to Step 2
     2. 🔄 Request changes to Step 1 (provide change direction)
     3. ⏭️  Resume from a different step (specify step number 0-5)
     4. ⏸️  Pause and create handover documentation"
   - Wait for user response

3. **Process user feedback**:
   - **Option 1 (Proceed)**: Continue to Step 2
   - **Option 2 (Request changes)**:
     - Ask user: "What changes would you like to make to Step 1?"
     - Capture Change Direction from user response
     - Set Resume From Step = 1
     - Loop back to Phase 2 with change requirements
     - After changes complete, return to this phase for confirmation
   - **Option 3 (Resume from different step)**:
     - Ask user: "Which step would you like to resume from (0-5)?"
     - Ask user: "Any change direction for that step? (optional)"
     - Set Resume From Step to specified step
     - Set Change Direction if provided
     - Skip to specified step
   - **Option 4 (Pause)**:
     - Run /handover to capture current state
     - Present: "Handover documentation created. Use /coding:takeover to resume later."
     - Exit workflow gracefully

4. **Run /handover command again** to capture latest state:

   ```
   /coding:handover --files=CONTEXT.md,RESEARCH.md,PLAN.md
   ```

**If Interactive Mode is NOT Enabled**:

- Skip this phase and proceed directly to Step 2

### Step 2: Implementation (Green Phase)

**Step Configuration**:

- **Purpose**: Implement minimal code to make tests pass using TDD Green phase principles
- **Input**: Code skeleton and test structure from Step 1
- **Output**: Minimal working implementation with all tests passing
- **Sub-workflow**: None
- **Parallel Execution**: No - single subagent

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 2: **SKIP this step entirely**, proceed to Step 3
   - If Resume From Step = 2: Execute this step with Change Direction if provided
   - If Resume From Step < 2: Execute this step normally

2. **Check Skip Steps**:
   - If 2 is in Skip Steps array: **SKIP this step entirely**, proceed to Step 3
   - Otherwise: Execute as normal

3. **Apply Change Direction** (if Resume From Step = 2 and Change Direction provided):
   - Include Change Direction in subagent instructions
   - Modify implementation approach based on direction
   - Update test requirements if needed
   - Example: "Change authentication to use JWT instead of sessions"

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason
   - If resuming with changes: Note change direction being applied

#### Phase 1: Planning (You)

**What You Do**:

1. **Receive inputs** from Step 1 (skeleton and test structure)
2. **Determine the standards** to send to subagent:
   - general-principles.md
   - error-handling-logging.md
   - typescript.md
   - functions.md
   - documentation.md
   - testing.md
3. **Create task assignment** for implementation
4. **Use TodoWrite** to create task for implementation
5. **Prepare task assignment** with skeleton context
6. **Queue single task** for execution

**OUTPUT from Planning**: Implementation task assignment as todo

#### Phase 2: Execution (Single Subagent)

**What You Send to Subagent**:

In a single message, you spin up **1** subagent to perform implementation.

- **[IMPORTANT]** When there are any issues reported, you must analyze and provide feedback for fixes
- **[IMPORTANT]** You MUST ask the subagent to ultrathink hard about minimal implementation
- **[IMPORTANT]** Use TodoWrite to update task status from 'pending' to 'in_progress' when dispatched

Request the subagent to perform the following steps with full detail:

    >>>
    **ultrathink: adopt the TDD Green Phase Expert mindset**

    - You're a **TDD Green Phase Expert** with deep expertise in minimal implementation who follows these technical principles:
      - **Minimal Implementation**: Write only enough code to make tests pass
      - **Test-Driven**: Let tests guide implementation decisions
      - **Quick Feedback**: Implement in small increments with frequent test runs
      - **Standards Compliance**: Follow all coding standards from the start

    **Read the following assigned standards** and follow them recursively (if A references B, read B too):

    - general-principles.md
    - error-handling-logging.md
    - typescript.md
    - functions.md
    - documentation.md
    - testing.md

    **Assignment**
    You're assigned to implement minimal code to make tests pass:

    - Replace TODO placeholders with working implementations
    - Focus on making tests pass, not adding extra features
    - Maintain type safety and error handling
    - Follow function design standards

    **Steps**

    1. **Implement minimal code**:
       - Replace TODO placeholders with simplest implementation
       - Focus only on making failing tests pass
       - Apply proper error handling per standards
       - Ensure type safety throughout
       - Use CODE DRAFTING PATTERNS for any remaining incomplete sections
    2. **Execute tests continuously**:
       - Run tests after each implementation increment
       - Verify Green phase achievement (tests passing)
       - Ensure no existing tests are broken
       - Confirm tests pass for correct reasons
    3. **Run test and lint scripts**:
       - Execute `npm run test` or equivalent
       - Execute `npm run lint` or equivalent
       - Report any issues found
       - Ensure all validation passes

    **Report**
    **[IMPORTANT]** You're requested to return the following:

    - Implementation files modified
    - Tests passing status
    - Green phase verification
    - Test and lint script execution results

    **[IMPORTANT]** You MUST return the following execution report (<1000 tokens):

    ```yaml
    status: success|failure|partial
    summary: 'Brief description of implementation'
    modifications: ['implementation-files-modified']
    outputs:
      implementation:
        files_modified: [...]
        tests_passing: true|false
        green_phase_verified: true|false
      validation:
        test_script: pass|fail
        lint_script: pass|fail
        all_tests_passing: true|false
    issues: ['issue1', 'issue2', ...]  # only if problems encountered
    ```
    <<<

#### Phase 3: Review (Single Subagent)

**What You Send to Review Subagent**:

In a single message, you spin up **1** review subagent to check implementation quality.

- **[IMPORTANT]** Review is read-only - subagent must NOT modify any resources
- **[IMPORTANT]** You MUST ask review subagent to be thorough and critical
- **[IMPORTANT]** Use TodoWrite to track review tasks separately from execution tasks

Request the review subagent to perform the following review with full scrutiny:

    >>>
    **ultrathink: adopt the Green Phase Validator mindset**

    - You're a **Green Phase Validator** with expertise in implementation review who follows these principles:
      - **Minimal Verification**: Ensure implementation is truly minimal
      - **Test Satisfaction**: Verify tests pass for correct reasons
      - **Standards Compliance**: Confirm adherence to all coding standards
      - **Quality Assessment**: Ensure implementation quality meets standards

    **Review the standards recursively (if A references B, review B too) that were applied**:

    - general-principles.md
    - error-handling-logging.md
    - typescript.md
    - functions.md
    - documentation.md
    - testing.md

    **Review Assignment**
    You're assigned to review the implementation created.

    **Review Steps**

    1. **Review implementation**:
       - Verify minimal approach (no extra features)
       - Check that tests pass for correct reasons
       - Validate error handling implementation
       - Assess code quality and maintainability
    2. **Check standards compliance**:
       - Verify all assigned standards are met
       - Check TypeScript compliance
       - Validate function design patterns
    3. **Verify test results**:
       - Confirm all tests are passing
       - Verify Green phase achievement
       - Check test/lint script execution

    **Report**
    **[IMPORTANT]** You're requested to verify and report:

    - Implementation quality and minimality
    - Test satisfaction verification
    - Standards compliance status
    - Green phase completion

    **[IMPORTANT]** You MUST return the following review report (<500 tokens):

    ```yaml
    status: pass|fail
    summary: 'Brief verification summary of implementation'
    checks:
      implementation_quality: pass|fail
      test_satisfaction: pass|fail
      standards_compliance: pass|fail
      green_phase_complete: pass|fail
    fatals: ['issue1', 'issue2', ...]  # Only critical blockers
    warnings: ['warning1', 'warning2', ...]  # Non-blocking issues
    recommendation: proceed|retry|rollback
    ```
    <<<

#### Phase 4: Decision (You)

**What You Do**:

1. **Analyze all reports** (execution + review)
2. **Apply decision criteria**:
   - Review implementation results
   - Review test satisfaction
   - Consider standards compliance
3. **Select next action**:
   - **PROCEED**: Implementation complete → Move to interactive confirmation
   - **FIX ISSUES**: Issues found → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
   - **ROLLBACK**: Critical failures → Revert changes → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
4. **Use TodoWrite** to update task list based on decision
5. **Run test and lint scripts** to confirm compliance:
   - Execute `npm run test` or equivalent
   - Execute `npm run lint` or equivalent
   - Report results

#### Phase 5: Interactive Confirmation (You)

**If Interactive Mode is Enabled**:

1. **Run /handover command** to create handover documentation

2. **Ask user for confirmation with options**:
   - Present: "Step 2 (Implementation - Green Phase) is complete. Choose an option:
     1. ✅ Proceed to Step 3
     2. 🔄 Request changes to Step 2 (provide change direction)
     3. ⏭️  Resume from a different step (specify step number 0-5)
     4. ⏸️  Pause and create handover documentation"
   - Wait for user response

3. **Process user feedback**:
   - **Option 1 (Proceed)**: Continue to Step 3
   - **Option 2 (Request changes)**:
     - Ask user: "What changes would you like to make to Step 2?"
     - Capture Change Direction from user response
     - Set Resume From Step = 2
     - Loop back to Phase 2 with change requirements
     - After changes complete, return to this phase for confirmation
   - **Option 3 (Resume from different step)**:
     - Ask user: "Which step would you like to resume from (0-5)?"
     - Ask user: "Any change direction for that step? (optional)"
     - Set Resume From Step to specified step
     - Set Change Direction if provided
     - Skip to specified step
   - **Option 4 (Pause)**:
     - Run /handover to capture current state
     - Present: "Handover documentation created. Use /coding:takeover to resume later."
     - Exit workflow gracefully

4. **Run /handover command again** to capture latest state

**If Interactive Mode is NOT Enabled**:

- Skip this phase and proceed directly to Step 3

### Step 3: Fix Test Issues & Standards Compliance

**Step Configuration**:

- **Purpose**: Fix issues found in test files including incorrect behavior, standards violations, and test-related problems while preserving test intent and correctness
- **Input**: Implementation from Step 2, all test files
- **Output**: Corrected tests with compliance report and correctness verification
- **Sub-workflow**: None
- **Parallel Execution**: Yes - can process multiple files in parallel (batch execution for >25 files)

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 3: **SKIP this step entirely**, proceed to Step 4
   - If Resume From Step = 3: Execute this step with Change Direction if provided
   - If Resume From Step < 3: Execute this step normally

2. **Check Skip Steps**:
   - If 3 is in Skip Steps array: **SKIP this step entirely**, proceed to Step 4
   - Otherwise: Execute as normal

3. **Apply Change Direction** (if Resume From Step = 3 and Change Direction provided):
   - Include Change Direction in batch subagent instructions
   - Add specific test fixes or improvements required
   - Focus correction efforts on areas mentioned in direction
   - Example: "Add edge case tests for null values and boundary conditions"

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason
   - If resuming with changes: Note change direction being applied to all batches

#### Phase 1: Planning (You)

**What You Do**:

1. **Receive implementation** from Step 2
2. **List all test files** using LS/Glob tools (do NOT read contents)
3. **Determine the minimum required standards** to send to subagents:
   - testing.md (REQUIRED)
   - typescript.md (REQUIRED)
   - documentation.md (REQUIRED)
4. **Create dynamic batches** following these rules:
   - Generate batches at runtime based on test files found
   - Limit each batch to max 10 test files
   - Assign one Correction Agent per batch for parallel execution
5. **Use TodoWrite** to create task list from all batches (each batch = one todo item with status 'pending')
6. **Prepare batch assignments** with specific file lists for each Correction Agent
7. **Queue all batches** for parallel execution by multiple Correction Agents

**OUTPUT from Planning**: Multiple batch task assignments as todos, ready for parallel dispatch

#### Phase 2: Execution (Subagents)

**What You Send to Subagents**:

In a single message, you spin up multiple Correction Agents to perform batch correction, up to **10** batches at a time.

- **[IMPORTANT]** When there are any issues reported, you must stop dispatching further agents until all issues have been rectified
- **[IMPORTANT]** You MUST ask all agents to ultrathink hard about the task and requirements
- **[IMPORTANT]** Use TodoWrite to update each batch's status from 'pending' to 'in_progress' when dispatched

Request each Correction Agent to perform the following steps with full detail:

    >>>
    **ultrathink: adopt the Test Correction Expert mindset**

    - You're a **Test Correction Expert** with deep expertise in test fixing who follows these technical principles:
      - **Batch Focus**: Process your assigned batch of test files (≤10 files) thoroughly
      - **Standards Discovery**: Dynamically discover and apply all relevant standards beyond the minimum 3
      - **Correctness First**: Fix test behavior and logic, never modify tests just to make them pass
      - **Standards Compliance**: Apply all discovered standards consistently across your batch
      - **Test-Only Modification**: NEVER modify source code - only test files, mocks, and fixtures

    **STEP 1: Dynamically discover all available standard files first**

    Before reading any assigned standards, use LS/Glob tools (NEVER `find` in bash) to list ALL available standard files in the plugins/coding/constitution/standards directory. Then determine which additional standards beyond the minimum 3 apply to test code.

    **Read the following MINIMUM REQUIRED standards** and follow them recursively (if A references B, read B too):

    - testing.md
    - typescript.md
    - documentation.md

    **Read any ADDITIONAL DISCOVERED standards** that apply to your test code batch:

    - [List additional standards you discovered that apply to test files]
    - [Include any standards referenced by the minimum 3 standards]

    **Assignment**
    You're assigned to fix issues in the following test files in Batch [X]:

    - [test file 1 from batch X]
    - [test file 2 from batch X]
    - [... up to 10 files maximum]

    **Steps**

    1. **Standards Discovery**: Use LS/Glob tools (NEVER `find` in bash) to list all available standard files and identify which apply to test code
    2. **Analysis Phase**: Read each test file in your batch to understand current issues, violations, and incorrect behavior
    3. **Issue Identification**: Identify correctness issues, standards violations, and improvement opportunities
    4. **Correction Planning**: Create fixing strategy focusing on correctness, standards compliance, and proper test patterns
    5. **Execution Phase**: Apply all corrections to fix issues and meet all applicable standards while preserving test intent
    6. **Verification Phase**: Run tests to ensure fixes work correctly and verify standards compliance - DO NOT modify tests to make them pass
    7. **Run test and lint scripts**:
       - Execute `npm run test` or equivalent
       - Execute `npm run lint` or equivalent
       - Report any issues found
       - Ensure all validation passes

    **CRITICAL CONSTRAINTS**:
    - ONLY modify test files, mock files, and fixture files
    - NEVER modify source code under test
    - Focus on test correctness, not on making tests pass
    - If tests fail due to source code issues, report this but do not fix the source code
    - Use LS/Glob tools for file discovery, NEVER use `find` in bash

    <IMPORTANT>
    **Handling Unused Code Errors**: When you encounter unused code or unused variable errors during validation:

    1. **Check design documentation first** (DESIGN.md, specification files) to verify if this code is part of planned functionality
    2. **Check handover documentation** (CONTEXT.md, PLAN.md, RESEARCH.md) to see if this is intentional incomplete implementation
    3. **If code is planned but not yet implemented**: Use `throw new Error('IMPLEMENTATION: [description of what needs implementing]', JSON.stringify({ unusedVar }))` to suppress the warning while clearly marking what needs implementation
    4. **Only remove code** that is genuinely unnecessary and not part of any planned feature

    This prevents accidental deletion of intentionally incomplete code while maintaining type safety.
    </IMPORTANT>

    **Report**
    **[IMPORTANT]** You're requested to return the following batch results:

    - Standards discovery results and which ones were applied
    - Modified test files list with specific issues fixed
    - Issue resolution summary with before/after status
    - Standards compliance verification for all applied standards
    - Test and lint script execution results
    - Any source code issues found that need developer attention

    **[IMPORTANT]** You MUST return the following execution report (<1000 tokens):

    ```yaml
    status: success|failure|partial
    summary: 'Batch [X]: Fixed Y issues across Z test files with standards compliance verification'
    modifications: ['test/file1.spec.ts', 'test/file2.spec.ts', ...]
    outputs:
      batch_info:
        batch_number: X
        files_processed: Z
        total_issues_fixed: Y
      standards_discovery:
        standards_found: ['list', 'of', 'all', 'discovered', 'standards']
        standards_applied: ['list', 'of', 'applied', 'standards']
        minimum_required: ['testing.md', 'typescript.md', 'documentation.md']
        additional_applied: ['other', 'standards', 'applied']
      issue_resolution:
        correctness_issues_fixed: X
        standards_violations_fixed: Y
        type_safety_issues_fixed: Z
        pattern_improvements: N
        total_fixes: M
      verification:
        tests_passing: true|false
        correctness_verified: true|false
        test_script: pass|fail
        lint_script: pass|fail
        standards_compliance:
          overall: pass|fail
          testing_standard: pass|fail
          typescript_standard: pass|fail
          documentation_standard: pass|fail
          [additional_standards]: pass|fail
        source_code_issues_found: ['list', 'of', 'source', 'issues', 'requiring', 'developer', 'attention']
    issues: ['issue1', 'issue2', ...]  # only if problems encountered
    ```
    <<<

#### Phase 3: Review (Subagents)

**When You Triggers Review**: Always performed for Step 3 to ensure all test files comply with all applied standards

**What You Send to Review Subagents**:

In a single message, you spin up Review Subagents to check quality for ALL batches, up to **10** review tasks at a time.

- **[IMPORTANT]** Review is read-only - subagents must NOT modify any resources
- **[IMPORTANT]** You MUST ask review subagents to be thorough and critical
- **[IMPORTANT]** Use TodoWrite to track review tasks separately from execution tasks

Request each Review Subagent to perform the following review with full scrutiny:

    >>>
    **ultrathink: adopt the Test Standards Review Specialist mindset**

    - You're a **Test Standards Review Specialist** with expertise in quality assurance who follows these principles:
      - **Comprehensive Compliance**: Verify ALL standards are met, including minimum required and additional discovered standards
      - **Recursive Standards Review**: When a standard references other standards, verify compliance with ALL referenced standards
      - **Critical Analysis**: Identify any deviation from standards requirements or remaining correctness issues
      - **Zero Tolerance**: Any standards violation or correctness issue must be flagged as a failure

    **Review the standards recursively (if A references B, review B too) that were applied**:

    - testing.md - Verify compliance with this standard and all its referenced standards
    - typescript.md - Verify compliance with this standard and all its referenced standards
    - documentation.md - Verify compliance with this standard and all its referenced standards
    - [Additional standards discovered and applied by execution agents]

    **Review Assignment**
    You're assigned to review the following test files that were modified in Batch [X]:

    - [test file 1]:
      - [Summary of what issues were fixed in this file]
    - [test file 2]:
      - [Summary of what issues were fixed in this file]
    - ...

    **Review Steps**

    1. **Read ALL Applied Standards**: Read all standards that were applied and identify ALL requirements including recursive references
    2. **Verify Minimum Standards**: Check each test file against ALL requirements in testing.md, typescript.md, documentation.md
    3. **Verify Additional Standards**: Check each test file against ALL requirements in additional standards discovered
    4. **Check Recursive References**: Verify any standards referenced by applied standards are also met
    5. **Verify Correctness**: Ensure test logic and behavior is correct and appropriate
    6. **Report Compliance**: Provide detailed pass/fail for each standard and correctness verification

    **Report**
    **[IMPORTANT]** You're requested to verify and report:

    - All applied standards compliance status (minimum + additional discovered)
    - Test correctness and logic verification
    - Complete verification matrix for the batch

    **[IMPORTANT]** You MUST return the following review report (<500 tokens):

    ```yaml
    status: pass|fail
    summary: 'Batch [X]: Verified Y test files against all applied standards and correctness requirements'
    checks:
      testing_standard: pass|fail
      typescript_standard: pass|fail
      documentation_standard: pass|fail
      additional_standards_complete: pass|fail
      correctness_verification: pass|fail
      batch_verification_complete: pass|fail
    standards_matrix:
      - file: 'test/file1.spec.ts'
        testing_std: pass|fail
        typescript_std: pass|fail
        documentation_std: pass|fail
        additional_std: pass|fail
        correctness: pass|fail
      - file: 'test/file2.spec.ts'
        testing_std: pass|fail
        typescript_std: pass|fail
        documentation_std: pass|fail
        additional_std: pass|fail
        correctness: pass|fail
    fatals: ['issue1', 'issue2', ...]  # Any standards violations or correctness issues found
    warnings: ['warning1', 'warning2', ...]  # Non-blocking issues
    recommendation: proceed|retry|rollback
    ```
    <<<

#### Phase 4: Decision (You)

**What You Do**:

1. **Analyze all batch reports** (execution + mandatory verification for Step 3)
2. **Apply decision criteria**:
   - Review any critical batch failures
   - Review mandatory verification results for standards compliance and correctness
   - Consider verification recommendations
3. **Select next action**:
   - **PROCEED**: All batches success or acceptable partial success → Move to interactive confirmation
   - **FIX ISSUES**: Partial success with minor issues → Create new batches for failed items and perform phase 2 again → Review following phase 3 again → ||repeat||
   - **ROLLBACK**: Critical failures → Revert changes → Create new batches for failed items and perform phase 2 again → Review following phase 3 again → ||repeat||
4. **Use TodoWrite** to update task list based on decision
5. **Run test and lint scripts** to confirm compliance:
   - Execute `npm run test` or equivalent
   - Execute `npm run lint` or equivalent
   - Report results

#### Phase 5: Interactive Confirmation (You)

**If Interactive Mode is Enabled**:

1. **Run /handover command** to create handover documentation

2. **Ask user for confirmation with options**:
   - Present: "Step 3 (Fix Test Issues & Standards Compliance) is complete. Choose an option:
     1. ✅ Proceed to Step 4
     2. 🔄 Request changes to Step 3 (provide change direction)
     3. ⏭️  Resume from a different step (specify step number 0-5)
     4. ⏸️  Pause and create handover documentation"
   - Wait for user response

3. **Process user feedback**:
   - **Option 1 (Proceed)**: Continue to Step 4
   - **Option 2 (Request changes)**:
     - Ask user: "What changes would you like to make to Step 3?"
     - Capture Change Direction from user response
     - Set Resume From Step = 3
     - Loop back to Phase 2 with change requirements
     - After changes complete, return to this phase for confirmation
   - **Option 3 (Resume from different step)**:
     - Ask user: "Which step would you like to resume from (0-5)?"
     - Ask user: "Any change direction for that step? (optional)"
     - Set Resume From Step to specified step
     - Set Change Direction if provided
     - Skip to specified step
   - **Option 4 (Pause)**:
     - Run /handover to capture current state
     - Present: "Handover documentation created. Use /coding:takeover to resume later."
     - Exit workflow gracefully

4. **Run /handover command again** to capture latest state

**If Interactive Mode is NOT Enabled**:

- Skip this phase and proceed directly to Step 4

### Step 4: Optimize Test Structure & Fixtures

**Step Configuration**:

- **Purpose**: Fix issues in test fixtures and mocks, ensuring proper structure and organization while maintaining correctness
- **Input**: Fixed test files from Step 3
- **Output**: Corrected and optimized fixtures/mocks with proper organization and type safety
- **Sub-workflow**: None
- **Parallel Execution**: No - single subagent

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 4: **SKIP this step entirely**, proceed to Step 5
   - If Resume From Step = 4: Execute this step with Change Direction if provided
   - If Resume From Step < 4: Execute this step normally

2. **Check Skip Steps**:
   - If 4 is in Skip Steps array: **SKIP this step entirely**, proceed to Step 5
   - Otherwise: Execute as normal
   - **Common scenario**: Skip if no fixtures/mocks exist in project

3. **Apply Change Direction** (if Resume From Step = 4 and Change Direction provided):
   - Include Change Direction in batch subagent instructions
   - Focus optimization on specific fixture/mock areas mentioned
   - Adjust organization strategy based on direction
   - Example: "Consolidate duplicate fixtures and improve naming consistency"

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason (e.g., "no fixtures to optimize")
   - If resuming with changes: Note change direction being applied to all batches

#### Phase 1: Planning (You)

**What You Do**:

1. **Receive fixed files** from Step 3
2. **Scan for fixture/mock issues** using Grep tool (do NOT read full contents, NEVER use `find` in bash)
3. **Identify fixture/mock correction opportunities**:
   - Incorrect fixture definitions or mock behavior
   - Type safety issues in fixtures/mocks
   - Organizational problems
   - Standards violations in test support files
4. **Create dynamic batches** following these rules:
   - Generate batches at runtime based on fixture/mock patterns found
   - Limit each batch to max 10 related fixtures/mocks
   - Assign one Optimization Agent per batch for parallel execution
5. **Use TodoWrite** to create task list from all batches (each batch = one todo item with status 'pending')
6. **Prepare batch assignments** with specific fixture/mock lists for each Optimization Agent
7. **Queue all batches** for parallel execution by multiple Optimization Agents

**OUTPUT from Planning**: Multiple fixture batch assignments as todos, ready for parallel dispatch

#### Phase 2: Execution (Subagents)

**What You Send to Subagents**:

In a single message, you spin up multiple Optimization Agents to perform batch optimization in parallel, up to **10** batches at a time.

- **[IMPORTANT]** When there are any issues reported, you must stop dispatching further agents until all issues have been rectified
- **[IMPORTANT]** You MUST ask all agents to ultrathink hard about the task and requirements
- **[IMPORTANT]** Use TodoWrite to update each batch's status from 'pending' to 'in_progress' when dispatched

Request each Optimization Agent to perform the following steps with full detail:

    >>>
    **ultrathink: adopt the Fixture Correction Specialist mindset**

    - You're a **Fixture Correction Specialist** with deep expertise in test data management who follows these technical principles:
      - **Batch Focus**: Process your assigned batch of fixtures/mocks (≤10 items) thoroughly
      - **Correctness First**: Fix fixture/mock behavior and accuracy, ensure they represent realistic data
      - **Standards Compliance**: Apply all applicable testing standards to fixture/mock organization
      - **Test-Only Modification**: Only modify test support files - NEVER modify source code
      - **Verification Integration**: Self-verify all changes before reporting

    **Read the following assigned standards** and follow them recursively (if A references B, read B too):

    - general-principles.md
    - typescript.md
    - functions.md
    - documentation.md
    - testing.md

    **Assignment**
    You're assigned to fix issues in the following fixtures/mocks in Batch [X]:

    - [fixture/mock pattern 1 from batch X]
    - [fixture/mock pattern 2 from batch X]
    - [... up to 10 fixtures/mocks maximum]

    **Steps**

    1. **Analysis Phase**: Identify all fixture/mock issues in your batch including correctness, type safety, and organizational problems
    2. **Issue Identification**: Find incorrect behavior, standards violations, and improvement opportunities
    3. **Correction Planning**: Create fixing strategy focusing on accuracy, standards compliance, and proper organization
    4. **Execution Phase**: Apply all corrections to fix issues while ensuring fixtures/mocks represent accurate test data
    5. **Verification Phase**: Run tests to verify fixtures work correctly and maintain test accuracy
    6. **Run test and lint scripts**:
       - Execute `npm run test` or equivalent
       - Execute `npm run lint` or equivalent
       - Report any issues found
       - Ensure all validation passes

    **CRITICAL CONSTRAINTS**:
    - ONLY modify test fixtures, mock files, and test support files
    - NEVER modify source code under test
    - Focus on fixture/mock correctness and accuracy
    - Ensure fixtures represent realistic and valid test data
    - Use LS/Glob tools for file discovery, NEVER use `find` in bash

    **Report**
    **[IMPORTANT]** You're requested to return the following batch results:

    - Created/modified fixture/mock files with specific issues fixed
    - Correctness improvements applied to your batch
    - Standards compliance status for your batch
    - Test and lint script execution results
    - Any issues encountered during optimization

    **[IMPORTANT]** You MUST return the following execution report (<1000 tokens):

    ```yaml
    status: success|failure|partial
    summary: 'Batch [X]: Fixed Y fixture/mock issues with Z improvements applied'
    modifications: ['spec/fixtures/batch-X.fixture.ts', 'spec/mocks/batch-X.mock.ts', ...]
    outputs:
      batch_info:
        batch_number: X
        fixtures_processed: Y
        issues_fixed: Z
      corrections_applied:
        correctness_fixes: N
        type_safety_fixes: M
        organization_fixes: L
        standards_compliance_fixes: K
      fixtures_created:
        - file: 'spec/fixtures/batch-X.fixture.ts'
          fixtures: ['createUser', 'createAdminUser']
        - file: 'spec/mocks/batch-X.mock.ts'
          mocks: ['mockApiClient', 'mockResponse']
      verification:
        tests_passing: true|false
        fixtures_accurate: true|false
        test_script: pass|fail
        lint_script: pass|fail
        standards_compliance:
          testing_standard: pass|fail
          typescript_standard: pass|fail
          documentation_standard: pass|fail
          organization: pass|fail
    issues: ['issue1', 'issue2', ...]  # only if problems encountered
    ```
    <<<

#### Phase 3: Decision (You)

**What You Do**:

1. **Analyze all batch reports** from execution phase
2. **Apply decision criteria**:
   - Review any critical batch failures
   - Consider verification recommendations
3. **Select next action**:
   - **PROCEED**: All batches success or acceptable partial success → Move to interactive confirmation
   - **FIX ISSUES**: Partial success with minor issues → Create new batches for failed items and perform phase 2 again → Review following phase 3 again → ||repeat||
   - **ROLLBACK**: Critical failures → Revert changes → Create new batches for failed items and perform phase 2 again → Review following phase 3 again → ||repeat||
4. **Use TodoWrite** to update task list based on decision
5. **Run test and lint scripts** to confirm compliance:
   - Execute `npm run test` or equivalent
   - Execute `npm run lint` or equivalent
   - Report results

#### Phase 4: Interactive Confirmation (You)

**If Interactive Mode is Enabled**:

1. **Run /handover command** to create handover documentation

2. **Ask user for confirmation with options**:
   - Present: "Step 4 (Optimize Test Structure & Fixtures) is complete. Choose an option:
     1. ✅ Proceed to Step 5
     2. 🔄 Request changes to Step 4 (provide change direction)
     3. ⏭️  Resume from a different step (specify step number 0-5)
     4. ⏸️  Pause and create handover documentation"
   - Wait for user response

3. **Process user feedback**:
   - **Option 1 (Proceed)**: Continue to Step 5
   - **Option 2 (Request changes)**:
     - Ask user: "What changes would you like to make to Step 4?"
     - Capture Change Direction from user response
     - Set Resume From Step = 4
     - Loop back to Phase 2 with change requirements
     - After changes complete, return to this phase for confirmation
   - **Option 3 (Resume from different step)**:
     - Ask user: "Which step would you like to resume from (0-5)?"
     - Ask user: "Any change direction for that step? (optional)"
     - Set Resume From Step to specified step
     - Set Change Direction if provided
     - Skip to specified step
   - **Option 4 (Pause)**:
     - Run /handover to capture current state
     - Present: "Handover documentation created. Use /coding:takeover to resume later."
     - Exit workflow gracefully

4. **Run /handover command again** to capture latest state

**If Interactive Mode is NOT Enabled**:

- Skip this phase and proceed directly to Step 5

### Step 5: Refactoring & Documentation (Refactor Phase)

**Step Configuration**:

- **Purpose**: Refactor implementation for quality and maintainability, add comprehensive documentation, perform final quality validation
- **Input**: Implementation and optimized tests from Steps 2-4
- **Output**: Refactored code with documentation, final quality validation passing
- **Sub-workflow**: None
- **Parallel Execution**: No - single subagent

#### Step Execution Decision (You)

Before executing this step, check resume and skip parameters:

1. **Check Resume From Step**:
   - If Resume From Step > 5: Not applicable (this is the last step)
   - If Resume From Step = 5: Execute this step with Change Direction if provided
   - If Resume From Step < 5: Execute this step normally

2. **Check Skip Steps**:
   - If 5 is in Skip Steps array: **SKIP this step entirely**, proceed to workflow completion
   - Otherwise: Execute as normal

3. **Apply Change Direction** (if Resume From Step = 5 and Change Direction provided):
   - Include Change Direction in subagent instructions
   - Focus refactoring efforts on areas mentioned in direction
   - Adjust documentation focus based on requirements
   - Example: "Focus on improving naming conventions and adding comprehensive JSDoc"

4. **Use TodoWrite** to track this step:
   - If executing: Mark as 'in_progress'
   - If skipping: Mark as 'skipped' with reason
   - If resuming with changes: Note change direction being applied

#### Phase 1: Planning (You)

**What You Do**:

1. **Receive inputs** from Steps 2-4 (implementation and tests)
2. **Determine the standards** to send to subagent:
   - general-principles.md
   - typescript.md
   - functions.md
   - documentation.md
   - naming/files.md
3. **Create task assignment** for refactoring
4. **Use TodoWrite** to create task for refactoring
5. **Prepare task assignment** with implementation context
6. **Queue single task** for execution

**OUTPUT from Planning**: Refactoring task assignment as todo

#### Phase 2: Execution (Single Subagent)

**What You Send to Subagent**:

In a single message, you spin up **1** subagent to perform refactoring.

- **[IMPORTANT]** When there are any issues reported, you must analyze and provide feedback for fixes
- **[IMPORTANT]** You MUST ask the subagent to ultrathink hard about quality improvements
- **[IMPORTANT]** Use TodoWrite to update task status from 'pending' to 'in_progress' when dispatched

Request the subagent to perform the following steps with full detail:

    >>>
    **ultrathink: adopt the Refactoring Master mindset**

    - You're a **Refactoring Master** with deep expertise in code quality who follows these technical principles:
      - **Quality Focus**: Improve code structure without changing functionality
      - **Maintainability**: Make code easier to understand and modify
      - **Documentation Excellence**: Add comprehensive documentation following standards
      - **Test Protection**: Ensure all tests continue to pass throughout refactoring
      - **Standards Mastery**: Apply all coding standards for production quality

    **Read the following assigned standards** and follow them recursively (if A references B, read B too):

    - general-principles.md
    - typescript.md
    - functions.md
    - documentation.md
    - naming/files.md

    **Assignment**
    You're assigned to refactor implementation for quality and maintainability:

    - Improve code structure following general principles
    - Enhance readability and maintainability
    - Apply proper naming conventions
    - Add comprehensive JSDoc documentation
    - Perform final quality validation

    **Steps**

    1. **Refactor implementation**:
       - Improve code structure following standards
       - Enhance readability and maintainability
       - Apply proper naming conventions
       - Ensure code follows all established patterns
       - Run tests continuously to ensure no functionality is broken
    2. **Add comprehensive documentation**:
       - Add JSDoc comments following documentation standards
       - Include inline comments for complex logic
       - Document function parameters, return types, and behavior
       - Add usage examples where appropriate
    3. **Perform final quality validation**:
       - Run complete test suite to verify all tests still pass
       - Execute linting to ensure standards compliance
       - Verify code coverage remains at expected level
       - Confirm final implementation meets all quality gates
    4. **Run test and lint scripts**:
       - Execute `npm run test` or equivalent
       - Execute `npm run lint` or equivalent
       - Report any issues found
       - Ensure all validation passes

    **Report**
    **[IMPORTANT]** You're requested to return the following:

    - Refactored files with quality improvements
    - Documentation additions
    - Final quality validation results
    - Test and lint script execution results

    **[IMPORTANT]** You MUST return the following execution report (<1000 tokens):

    ```yaml
    status: success|failure|partial
    summary: 'Brief description of refactoring and documentation'
    modifications: ['refactored-files']
    outputs:
      refactoring:
        files_refactored: [...]
        improvements_applied: [...]
        tests_still_passing: true|false
      documentation:
        jsdoc_added: [...]
        inline_comments: [...]
        usage_examples: [...]
      validation:
        test_script: pass|fail
        lint_script: pass|fail
        all_tests_passing: true|false
        coverage_maintained: true|false
        quality_gates_passed: true|false
    issues: ['issue1', 'issue2', ...]  # only if problems encountered
    ```
    <<<

#### Phase 3: Review (Single Subagent)

**What You Send to Review Subagent**:

In a single message, you spin up **1** review subagent to check refactoring quality.

- **[IMPORTANT]** Review is read-only - subagent must NOT modify any resources
- **[IMPORTANT]** You MUST ask review subagent to be thorough and critical
- **[IMPORTANT]** Use TodoWrite to track review tasks separately from execution tasks

Request the review subagent to perform the following review with full scrutiny:

    >>>
    **ultrathink: adopt the Quality Assurance Master mindset**

    - You're a **Quality Assurance Master** with expertise in code quality review who follows these principles:
      - **Quality Verification**: Ensure refactoring improved code quality
      - **Documentation Review**: Verify documentation completeness and accuracy
      - **Standards Enforcement**: Confirm adherence to all coding standards
      - **Production Readiness**: Assess overall production readiness

    **Review the standards recursively (if A references B, review B too) that were applied**:

    - general-principles.md
    - typescript.md
    - functions.md
    - documentation.md
    - naming/files.md

    **Review Assignment**
    You're assigned to review the refactored implementation and documentation.

    **Review Steps**

    1. **Review refactoring**:
       - Verify quality improvements without functionality changes
       - Check that all tests still pass after refactoring
       - Validate code structure and maintainability
       - Assess overall code quality
    2. **Review documentation**:
       - Verify JSDoc completeness and accuracy
       - Check inline comments for clarity
       - Validate documentation standards compliance
    3. **Check standards compliance**:
       - Verify all assigned standards are met
       - Check naming conventions compliance
       - Validate overall production readiness
    4. **Verify final validation**:
       - Confirm all tests passing
       - Verify lint checks passing
       - Check quality gates satisfaction

    **Report**
    **[IMPORTANT]** You're requested to verify and report:

    - Refactoring quality and improvements
    - Documentation completeness and quality
    - Standards compliance status
    - Production readiness assessment

    **[IMPORTANT]** You MUST return the following review report (<500 tokens):

    ```yaml
    status: pass|fail
    summary: 'Brief verification summary of refactoring and documentation'
    checks:
      refactoring_quality: pass|fail
      documentation_quality: pass|fail
      standards_compliance: pass|fail
      production_readiness: pass|fail
    fatals: ['issue1', 'issue2', ...]  # Only critical blockers
    warnings: ['warning1', 'warning2', ...]  # Non-blocking issues
    recommendation: proceed|retry|rollback
    ```
    <<<

#### Phase 4: Decision (You)

**What You Do**:

1. **Analyze all reports** (execution + review)
2. **Apply decision criteria**:
   - Review refactoring results
   - Review documentation quality
   - Consider production readiness
3. **Select next action**:
   - **PROCEED**: Refactoring complete → Move to interactive confirmation
   - **FIX ISSUES**: Issues found → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
   - **ROLLBACK**: Critical failures → Revert changes → Create new task and perform phase 2 again → Review following phase 3 again → ||repeat||
4. **Use TodoWrite** to update task list based on decision
5. **Run test and lint scripts** to confirm compliance:
   - Execute `npm run test` or equivalent
   - Execute `npm run lint` or equivalent
   - Report results

#### Phase 5: Interactive Confirmation (You)

**If Interactive Mode is Enabled**:

1. **Run /handover command** to create handover documentation

2. **Ask user for confirmation with options**:
   - Present: "Step 5 (Refactoring & Documentation) is complete. Choose an option:
     1. ✅ Complete workflow
     2. 🔄 Request changes to Step 5 (provide change direction)
     3. ⏭️  Resume from a different step (specify step number 0-5)
     4. ⏸️  Pause and create handover documentation"
   - Wait for user response

3. **Process user feedback**:
   - **Option 1 (Complete)**: Proceed to workflow completion
   - **Option 2 (Request changes)**:
     - Ask user: "What changes would you like to make to Step 5?"
     - Capture Change Direction from user response
     - Set Resume From Step = 5
     - Loop back to Phase 2 with change requirements
     - After changes complete, return to this phase for confirmation
   - **Option 3 (Resume from different step)**:
     - Ask user: "Which step would you like to resume from (0-5)?"
     - Ask user: "Any change direction for that step? (optional)"
     - Set Resume From Step to specified step
     - Set Change Direction if provided
     - Skip to specified step
   - **Option 4 (Pause)**:
     - Run /handover to capture current state
     - Present: "Handover documentation created. Use /coding:takeover to resume later."
     - Exit workflow gracefully

4. **Run /handover command again** to capture final state

**If Interactive Mode is NOT Enabled**:

- Skip this phase and proceed directly to workflow completion

### Workflow Completion

**Report the workflow output as specified**:

```yaml
workflow: write-code
status: completed
outputs:
  code_skeleton:
    files_created: ['src/component.ts', 'src/utils.ts']
    todo_placeholders: ['authentication logic', 'validation logic', ...]
    structure_validated: true
  test_suite:
    files_created: ['src/component.spec.ts', 'src/utils.spec.ts']
    coverage_percentage: 100
    tests_count: 25
    red_phase_verified: true
  implementation_code:
    files_modified: ['src/component.ts', 'src/utils.ts']
    green_phase_verified: true
    standards_compliant: true
  fixed_tests:
    files_fixed: ['src/component.spec.ts']
    issues_resolved: 5
    standards_violations_fixed: 3
    standards_applied: ['testing.md', 'typescript.md', 'documentation.md']
  optimized_fixtures:
    files_created: ['src/fixtures/component.fixture.ts']
    fixtures_count: 8
    mocks_count: 4
    organization_improved: true
  refactored_code:
    files_refactored: ['src/component.ts', 'src/utils.ts']
    quality_improvements: ['naming', 'structure', 'documentation']
    documentation_added: true
  quality_validation:
    linting_passed: true
    type_checking_passed: true
    all_tests_passing: true
    coverage_maintained: 100
  tdd_cycle:
    step_0_design_discovery: completed
    step_1_skeleton_and_tests: completed
    step_2_implementation: completed
    step_3_fix_tests: completed
    step_4_optimize_fixtures: completed
    step_5_refactoring: completed
    cycle_verified: true
summary: |
  Successfully implemented [Feature Name] using comprehensive TDD methodology.
  Discovered design specifications, created complete code skeleton and test suite with
  100% coverage, implemented minimal working code, fixed [N] test issues, optimized
  [M] fixtures/mocks, and refactored for quality. All 5 steps of the enhanced TDD cycle
  completed successfully with continuous quality validation.
```

**Finalization Instructions**:

1. **Run Final Test Suite**: Execute all tests to verify complete functionality
2. **Verify Complete Coverage**: Ensure 100% test coverage maintained
3. **Review All Documentation**: Confirm comprehensive documentation added
4. **Check Quality Gates**: Validate all linting and type checking passes
5. **Assess Production Readiness**: Confirm implementation ready for production
6. **Review Handover Notes**: If interactive mode used, review all handover documentation

**Important Notes**:

- Complete TDD lifecycle followed: Design → Skeleton → Test → Implement → Fix → Optimize → Refactor
- Test fixes focused on correctness, not artificially making tests pass
- All standards violations resolved across implementation and tests
- Fixture and mock improvements enhance test maintainability and accuracy
- Interactive mode provided user feedback loops at each major step
- Continuous quality validation ensured production readiness throughout
